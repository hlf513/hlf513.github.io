{"pages":[{"title":"About","date":"2017-11-05T11:04:38.000Z","path":"about/index.html","text":""},{"title":"Categories","date":"2017-11-05T11:03:47.000Z","path":"categories/index.html","text":""},{"title":"Tags","date":"2017-11-05T11:02:00.000Z","path":"tags/index.html","text":""}],"posts":[{"title":"通过源码学习 Go 的生命周期","date":"2019-07-14T08:26:00.000Z","path":"2019/通过源码学习-go-的生命周期/","text":"当我们学习一个新事物时，一定要做到「知其然知其所以然」。最近看了一些 go 的源码，对 go 的设计有了更深的认识，也让自己在工作中使用的更得心应手。 本文基于以下版本：1go version go1.12.7 darwin/amd64 四个重要结构首先，我们了解下这四个核心的 struct，有助于帮助我们理解下文。 schedt src/runtime/runtime2.go 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647type schedt struct&#123; // ... // M 相关 midle muintptr // idle m's waiting for work nmidle int32 // number of idle m's waiting for work nmidlelocked int32 // number of locked m's waiting for work mnext int64 // number of m's that have been created and next M ID maxmcount int32 // maximum number of m's allowed (or die) nmsys int32 // number of system m's not counted for deadlock nmfreed int64 // cumulative number of freed m's // ... // P 相关 pidle puintptr // idle p's npidle uint32 nmspinning uint32 // See \"Worker thread parking/unparking\" comment in proc.go. // G 全局队列 runq gQueue runqsize int32 // Global cache of dead G's. gFree struct &#123; lock mutex stack gList // Gs with stacks noStack gList // Gs without stacks n int32 &#125; // ... // 等待释放的 M 列表 freem *m // ... // GC 、sysmon相关 gcwaiting uint32 // gc is waiting to run stopwait int32 stopnote note sysmonwait uint32 sysmonnote note // ...&#125; g src/runtime/runtime2.go 12345678910111213141516171819202122232425262728293031323334353637type g struct &#123; // stack 相关 stack stack // offset known to runtime/cgo stackguard0 uintptr // offset known to liblink stackguard1 uintptr // offset known to liblink // ... // 当前关联的 M m *m // current m; offset known to arm liblink // ... // 参数地址 param unsafe.Pointer // passed parameter on wakeup // ... // GC 相关 preemptscan bool // preempted g does scan for gc gcscandone bool // g has scanned stack; protected by _Gscan bit in status gcscanvalid bool // false at start of gc cycle, true if G has not run since last scan; TODO: remove? // ... waiting *sudog // sudog structures this g is waiting on (that have a valid elem ptr); in lock order // ... // 定时器 timer *timer // cached timer for time.Sleep // select selectDone uint32 // are we participating in a select and did someone win the race? // Per-G GC state gcAssistBytes int64&#125; m src/runtime/runtime2.go 1234567891011121314151617181920212223242526272829303132333435363738394041424344type m struct &#123; // ... // P 相关 p puintptr // attached p for executing go code (nil if not executing go code) nextp puintptr oldp puintptr // the p that was attached before executing a syscall // ... // M 自旋状态 spinning bool // m is out of work and is actively looking for work blocked bool // m is blocked on a note inwb bool // m is executing a write barrier newSigstack bool // minit on C thread called sigaltstack printlock int8 // cgo incgo bool // m is executing a cgo call // 等待 G 的数量 freeWait uint32 // if == 0, safe to free g0 and delete m (atomic) // ... // cgo ncgocall uint64 // number of cgo calls in total ncgo int32 // number of cgo calls currently in progress cgoCallersUse uint32 // if non-zero, cgoCallers in use temporarily cgoCallers *cgoCallers // cgo traceback if crashing in cgo call park note createstack [32]uintptr // stack that created this thread. lockedExt uint32 // tracking for external LockOSThread lockedInt uint32 // tracking for internal lockOSThread nextwaitm muintptr // next m waiting for lock // ... // OS 线程 thread uintptr // thread handle // 待释放的 M freelink *m // on sched.freem // ...&#125; p src/runtime/runtime2.go 123456789101112131415161718192021222324252627282930313233343536373839404142type p struct &#123; // 相关联的 M m muintptr // back-link to associated m (nil if idle) mcache *mcache racectx uintptr // G 本地队列 // Queue of runnable goroutines. Accessed without lock. runqhead uint32 runqtail uint32 runq [256]guintptr // 下个可被执行的 G runnext guintptr // Available G's (status == Gdead) gFree struct &#123; gList n int32 &#125; // sudog 相关 sudogcache []*sudog sudogbuf [128]*sudog palloc persistentAlloc // per-P to avoid mutex // Per-P GC state gcAssistTime int64 // Nanoseconds in assistAlloc gcFractionalMarkTime int64 // Nanoseconds in fractional mark worker gcBgMarkWorker guintptr gcMarkWorkerMode gcMarkWorkerMode // gcMarkWorkerStartTime is the nanotime() at which this mark // worker started. gcMarkWorkerStartTime int64 // gcw is this P's GC work buffer cache. The work buffer is // filled by write barriers, drained by mutator assists, and // disposed on certain GC state transitions. gcw gcWork&#125; 生命周期Go 启动引导文件是汇编写的，根据不同的系统，引导文件不同；文件存放于 runtime/asm_*.s: 1234567891011121314151617CALL runtime·args(SB)CALL runtime·osinit(SB)CALL runtime·schedinit(SB)// create a new goroutine to start programMOVQ $runtime·mainPC(SB), AX // entryPUSHQ AXPUSHQ $0 // arg sizeCALL runtime·newproc(SB)POPQ AXPOPQ AX// start this MCALL runtime·mstart(SB)CALL runtime·abort(SB) // mstart should never returnRET runtime.osinit 根据 OS 不同，在不同的文件中：src/runtime/os_*.go 获取 cpu 的核数 123func osinit() &#123; ncpu = getproccount()&#125; runtime·schedinit src/runtime/proc.go schedt 结构初始化: 设置 M 的最大数量为 10000 stack、args、envs、gc 等初始化 P 数量初始化；此时 STW，sched 上锁，生成的 P 会被放入 schedt.pidle 中 12345678910111213141516func schedinit()&#123; // ... // M 最多为10000个 sched.maxmcount = 10000 // 根据 CPU 核数、GOMAXPROCS调整 procs procs := ncpu if n, ok := atoi32(gogetenv(\"GOMAXPROCS\")); ok &amp;&amp; n &gt; 0 &#123; procs = n &#125; // 根据 procs 调整 P 的数量 if procresize(procs) != nil &#123; throw(\"unknown runnable goroutine during bootstrap\") &#125; // ...&#125; runtime·newproc src/runtime/proc.go 创建一个 G 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647func newproc(size int32,fn *funcval)&#123; // ... systemstack(func() &#123; newproc1(fn, (*uint8)(argp), siz, gp, pc) &#125;) // ...&#125;func newproc1(fn *funcval, argp *uint8, narg int32, callergp *g, callerpc uintptr) &#123; // ... // 从 gFree 中获取 G；若本地为空，则从全局拿32个放入本地 newg := gfget(_p_) // ... // 把 G 放入到 p.runnext，若本地队列满了(&gt;256),则从本地队列拿一半+当前 G 放入全局队列) runqput(_p_, newg, true) // 若有空闲 P， M0 已启动，并且没有自旋 M（启动过程中不会执行） if atomic.Load(&amp;sched.npidle) != 0 &amp;&amp; atomic.Load(&amp;sched.nmspinning) == 0 &amp;&amp; mainStarted &#123; // 尝试再添加一个 P 来执行 G wakep() &#125;&#125;// 引导过程中不会执行以下函数func wakep()&#123; // ... // 获取一个空闲 P，M；并绑定 startm(nil, true)&#125;func startm(_p_ *p, spinning bool) &#123; lock(&amp;sched.lock) if _p_ == nil &#123; // 从 schedt.pidle 中获取空闲的 P _p_ = pidleget() // ... &#125; // ... // 从 schedt.midle 中获取空闲的 M mp := mget() unlock(&amp;sched.lock) if mp == nil &#123; // ... // 创建新的 M（ OS thread） newm(fn, _p_) return &#125;&#125; runtime·mstart src/runtime/proc.go 找到一个 P，并绑定一个 M，然后执行 G123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293func mstart()&#123; // 获取当前 G _g_ := getg() // ... mstart1() // ... mexit(osStack)&#125;func mstart1()&#123; // 获取当前 G _g_ := getg() // ... // 启动 M0 if _g_.m == &amp;m0 &#123; mstartm0() &#125; // ... if _g_.m != &amp;m0 &#123; // 关联 P 和 M acquirep(_g_.m.nextp.ptr()) _g_.m.nextp = 0 &#125; // 找到一个可执行的 G，并执行 schedule()&#125;func schedule()&#123; _g_ := getg() // // ... if gp == nil &#123; // 1/61 的几率从全局取 G，调用 rungput 放入本地队列 if _g_.m.p.ptr().schedtick%61 == 0 &amp;&amp; sched.runqsize &gt; 0 &#123; lock(&amp;sched.lock) gp = globrunqget(_g_.m.p.ptr(), 1) unlock(&amp;sched.lock) &#125; &#125; if gp == nil &#123; // 从本地队列取 G gp, inheritTime = runqget(_g_.m.p.ptr()) if gp != nil &amp;&amp; _g_.m.spinning &#123; throw(\"schedule: spinning with local work\") &#125; &#125; if gp == nil &#123; // 循环：本地队列 -&gt; 全局队列 -&gt; poll network -&gt; 偷其他 P 一半 G -&gt; 检查 P -&gt; GC gp, inheritTime = findrunnable() // blocks until work is available &#125; // 若是自旋 M, 则停止当前 M，然后调用 wakep 开启新的自旋 M if _g_.m.spinning &#123; resetspinning() &#125; // 执行 G，从 G0 -&gt; G execute(gp, inheritTime)&#125;func main()&#123; g := getg() // ... if sys.PtrSize == 8 &#123; maxstacksize = 1000000000 &#125; else &#123; maxstacksize = 250000000 &#125; // ... // 执行用户的 init() fn := main_init // make an indirect call, as the linker doesn't know the address of the main package when laying down the runtime // ... // 执行 main.main() fn = main_main // make an indirect call, as the linker doesn't know the address of the main package when laying down the runtime // ... // 退出 exit(0)&#125;","tags":[{"name":"go","slug":"go","permalink":"http://www.helongfei.com/tags/go/"}],"categories":[{"name":"go","slug":"go","permalink":"http://www.helongfei.com/categories/go/"}]},{"title":"Go 并发编程-应用篇","date":"2019-07-11T17:16:00.000Z","path":"2019/go-并发编程-应用篇/","text":"当提到并发编程的时候，人们往往会想到多线程，而 Go 最被人熟知的是借鉴 CSP 的 gorountine &amp; channel 并发模式，那 Go 中是否支持类似传统多线程的并发编程方式呢？答案是支持；因为 Go 的 Sync 包给我们提供了互斥锁、原子操作、条件变量等同步原语。 本文主要介绍下同步原语的用法，并发下的数据存储，以及 Goroutine 的使用方式和注意事项。 同步原语Mutex 互斥锁，1.9 引入「饥饿模式」解决了尾延时（队列头的 Goroutine 会被新建 Goroutine 抢占锁） 1234567var s sync.RWMutexs.Lock()// handler somethings.Unlock() RWMutex 读写互斥锁，用于并发读 1234567var s sync.RWMutexs.RLock()// handler somethings.RUnlock() Once 只执行一次；即使执行的是不同的 func，也只会执行一次。 Once 只有一个 Do 方法，参数是函数 12345678910111213var s sync.OnceonceFunc := func()&#123; print(\"once\")&#125;onceFunc2 := func()&#123; print(\"once\")&#125;// 只会输出一个 onces.Do(onceFunc)s.Do(onceFunc2) Atomic 原子操作 sync/atomic 提供了针对整型、通用类型的原子操作。 针对整型的方法有：加(Add)、CAS(交换并比较 compare and swap)、存储(store)、读取(load)以及交换(swap)： 12345678910111213// 还支持 uint32、int64 等var i int32i = 1atomic.AddInt32(&amp;i, 2)// 不会改变 i 的值atomic.CompareAndSwapInt32(&amp;i, 2, 10)// 会改变 i 的值atomic.CompareAndSwapInt32(&amp;i, 3, 11)// 交换值，并返回旧值的指针atomic.SwapInt32(&amp;i, -1)fmt.Println(atomic.LoadInt32(&amp;i))// 存储值atomic.StoreInt32(&amp;i, 1) 针对通用类型的方法有：Store 存储、Load 读取 12345678var atomicVal atomic.Valuestr := \"hello\"// 存储atomicVal.Store(str)// 读取fmt.Println(atomicVal.Load()) Cond 让 Goroutine 在某个条件下被阻塞/唤醒 Cond 提供三个方法：Wait 阻塞、Signal 唤醒、Broadcast 唤醒所有 Goroutine； 12345678910111213141516171819202122232425262728 func main() &#123; // 初始化需要一个锁 c := sync.NewCond(&amp;sync.Mutex&#123;&#125;) for i := 0; i &lt; 10; i++ &#123; go listen(c) &#125; go broadcast(c) ch := make(chan os.Signal, 1) signal.Notify(ch, os.Interrupt) &lt;-ch&#125;func listen(c *sync.Cond) &#123; c.L.Lock() c.Wait() // 阻塞；以下代码暂不执行 fmt.Println(\"listen\") c.L.Unlock()&#125;func broadcast(c *sync.Cond) &#123; c.L.Lock() c.Broadcast() // 唤醒所有的 Goroutine fmt.Println(\"release\") c.L.Unlock()&#125; 调用 Singal 会唤醒阻塞时间最长的 Goroutine。 WaitGroup 最常用的同步机制，多用于等待一批 Goroutine 的返回 WaitGroup 提供三个方法：Add 计数、Done 完成（计数-1）、Wait 阻塞到计数为0为止 12345678910111213var wg sync.WaitGroupfor i := 0; i &lt; 10; i++ &#123; wg.Add(1) go func() &#123; defer func() &#123; wg.Done() &#125;() fmt.Println(\"handler something\") &#125;()&#125;wg.Wait() 数据存储Map 1.9 引入的并发安全 sync.map（1.9 之前的 map 在不加锁的前提下进行写操作会报错） Map 提供五个方法：Store 存储键值对、LoadOrStore 读取或存储键值对、Load 读取键值对、Delete 删除键值对、Range 遍历键值对 1234567891011121314var m sync.Mapm.Store(\"k\", \"v\")m.Load(\"k\")// 不会覆盖 k 的值m.LoadOrStore(\"k\", \"v1\")// 会覆盖 k 的值m.Store(\"k\", map[string]string&#123; \"k1\": \"v1\",&#125;)m.Range(func(key, value interface&#123;&#125;) bool &#123; fmt.Println(key, value) return false&#125;) Pool 并发安全，用于存储可复用的临时对象，以减少垃圾回收的压力 Pool 提供了两个方法：Get 获取对象，Put 放入对象 12345678910111213// 一个[]byte的对象池，每个对象为一个[]bytevar bytePool = sync.Pool&#123; // 获取对象不存在时则创建 New: func() interface&#123;&#125; &#123; b := make([]byte, 1024) return &amp;b &#125;,&#125;// 获取对象obj := bytePool.Get().(*[]byte)_ = obj// 对象放入池子bytePool.Put(obj) 上下文 Context当我们在 Goroutine 中再次产生一个 Goroutine 的时候，若前者异常退出，理论上后者也应该退出，否则就是对资源的浪费。 Context 的主要作用就是在不同的 Goroutine 之间同步请求特定的数据、取消信号以及处理请求的截止日期。 可以把 Context 类比为一棵树结构： 根节点不可取消；那生成根节点的方法有：context.Background()、context.TODO()；两者的区别是没有本质区别，当不知道使用什么的时候用 TODO()；常用的是 Background()。 生成子节点的方法有：WithCancel 手动取消、WithDeadline 定时取消、WithTImeout 定时取消、WithValue 存键值对 12345678910111213141516ctx, cancel := context.WithCancel(context.Background())// 手动取消cancel()// 定时取消 - 截止d := time.Now().Add(50 * time.Millisecond)ctx, cancel := context.WithDeadline(context.Background(), d)defer cancel()// 定时取消 - 超时ctx, cancel := context.WithTimeout(context.Background(), 50*time.Millisecond)defer cancel()// 存键值对(先找子节点再找父节点)ctx := context.WithValue(context.Background(), \"kkk\", \"vvv\")fmt.Println(ctx.Value(\"kkk\")) 键值对不要存过多的参数，一般常用来存储 global trace id。 ChannelChannel 分为有 buffer channel 、无 buffer channel；若是无 buffer 的 channel，在一端没有准备好数据之前，另一端会阻塞；若是有 buffer 的 channel，则 buffer 未满之前是不阻塞的。 使用起来比较简单；提供四个方法： 创建 channel 数据写入 channel 读取 channel 数据 关闭 channel（无法写入数据，但可以读取） 123456789101112131415161718192021222324252627282930func main() &#123; // 无缓存 ch1 := make(chan int) // 有缓存 //ch1 := make(chan int,10) // 接收数据 go receive(ch1) // 发送数据 send(ch1) // 关闭 channel close(ch1)&#125;func send(ch chan int) &#123; for i := 0; i &lt; 2; i++ &#123; ch &lt;- i &#125;&#125;func receive(ch chan int) &#123; d := &lt;-ch fmt.Println(\"one\", d) for d := range ch &#123; fmt.Println(\"two\", d) &#125;&#125; channel 还支持只读、只写操作： 1234567891011121314151617181920212223func main() &#123; var ch = make(chan int) go receive(ch) send(ch) close(ch) time.Sleep(1 * time.Second)&#125;// 只读func receive(ch &lt;-chan int) &#123; for v := range ch &#123; fmt.Println(v) &#125;&#125;// 只写func send(ch chan&lt;- int) &#123; for i := 0; i &lt;= 10; i++ &#123; ch &lt;- i &#125; // 只写里可以执行关闭 channel 的操作 // close(ch)&#125; 使用场景 信号传递把数据当做信号放入 channel；一般使用无 buffer 的 channel；常和 WaitGroup 配合控制并发数。 123456789101112func main() &#123; ch := make(chan int) go func() &#123; fmt.Println(\"handler something\") // 通知 main goroutine 任务处理完毕 ch &lt;- 1 &#125;() // 阻塞；等待新建 goroutine 中处理任务 &lt;-ch&#125; 消息队列把数据放入 channel 等待消费；一般使用有 buffer 的 channel。 多个 channel 串联为 Pipeline每个 channel 的输出当做另一个 channel 的输入。 12345678910111213141516171819202122232425262728293031323334func main() &#123; ch1 := make(chan int) ch2 := make(chan int) // 计数 go counter(ch1) // 平方 go square(ch1, ch2) // 输出 go output(ch2) time.Sleep(1 * time.Second)&#125;func counter(ch1 chan int) &#123; for i := 0; i &lt; 5; i++ &#123; ch1 &lt;- i &#125; close(ch1)&#125;func square(ch1 chan int, ch2 chan int) &#123; for i := range ch1 &#123; i *= i ch2 &lt;- i &#125; close(ch2)&#125;func output(ch2 chan int) &#123; for i := range ch2 &#123; fmt.Println(i) &#125;&#125; Select多路复用；语法类似 Switch，有 default 则不阻塞，无 default 则： 条件都未成立，则阻塞 条件分支某个成立，则执行 条件分支都成立，则随机选择一个 1234567891011for &#123; select &#123; case d1 := &lt;-ch1: fmt.Println(d1) case &lt;-time.After(3 * time.Second): // 设置超时时间 fmt.Println(\"timeout\") break default: fmt.Println(\"default\") &#125;&#125; Goroutine 泄露Goroutine 的开销很小，但若是使用不当，造成 GC 无法回收的话，久而久之就会引起内存耗尽。 常见场景 nil channel 永远阻塞 123456789func main() &#123; var ch chan int go nilChannel(ch)&#125;func nilChannel(ch chan int) &#123; &lt;-ch&#125; 没有接收者的 channel 例：并发请求两个搜索引擎，响应结果写入 channel；我们使用最先收到的响应，丢失之后的响应，这样会造成后者 goroutine 一直阻塞解决方案：保证 channel 里的数据都会被读取，或者使用 context 取消其他请求。 1234567891011121314151617181920212223242526272829func main() &#123; var ch = make(chan int) // 查询结果 go func() &#123; go baidu(ch) go bing(ch) &#125;() // 输出查询结果 go res(ch) time.Sleep(1 * time.Second) &#125; func baidu(ch chan int) &#123; res, _ := http.Get(\"https://baidu.com\") ch &lt;- res.StatusCode + 1 &#125; func bing(ch chan int) &#123; res, _ := http.Get(\"https://cn.bing.com\") ch &lt;- res.StatusCode + 2 &#125; func res(ch chan int) &#123; code := &lt;-ch fmt.Println(code, runtime.NumGoroutine()) &#125; 没有接收者的 channel 程序死循环 由此可以看出，goroutine 泄露都是因为使用不当造成的；所以我们在使用 goroutine 的时候一定要小心。 泄露检测 观察 runtime.NumGoroutine pprof 通过 web 查看 net/http/pprof 123456789import ( \"log\" \"net/http\" _ \"net/http/pprof\")...log.Println(http.ListenAndServe(\"localhost:6060\", nil)) 访问 http://localhost:6060/debug/pprof/goroutine?debug=1 查看 gorutine 状态 通过 stdout 查看 runtime/pprof 12345678import ( \"os\" \"runtime/pprof\")...pprof.Lookup(\"goroutine\").WriteTo(os.Stdout, 1) gops https://github.com/google/gops 12345678import \"github.com/google/gops/agent\"...if err := agent.Start(); err != nil &#123; log.Fatal(err)&#125;time.Sleep(time.Hour) leaktest https://github.com/fortytw2/leaktest 基本原理：在测试的开始和结束的时候，利用 runtime.Stack 获取活跃 goroutine 的堆栈跟踪。如果在测试完成后还有一些新的 goroutine，那么将其归类为泄露。 参考资料 同步原语与锁 Golang非CSP并发模型外的其他并行方法总结 Goroutine 泄露","tags":[{"name":"go","slug":"go","permalink":"http://www.helongfei.com/tags/go/"}],"categories":[{"name":"go","slug":"go","permalink":"http://www.helongfei.com/categories/go/"}]},{"title":"使用 OpenResty 实现 Grafana 免登录","date":"2019-06-20T10:44:00.000Z","path":"2019/使用-openresty-实现-grafana-免登录/","text":"背景公司内部都有管理后台，一般都会把第三方软件集成到后台，收敛登录入口。 本文主要介绍一种集成 Grafana 的方法。 问题假设，只有一个 token ，通过这个 token 可以获取到用户信息，在这种情况下，怎么可以免登录进入 Grafana？ 例：访问：http://grafana.com?token=xxxxxxx 后，不应该跳转到 http://grafana.com/login ，而应该直接进入 http://grafana.com/home 基本思路通过查看文档，可以发现 Grafana 支持多种权限认证；但没有一个能完美解决我们问题的方案；唯一比较接近的是 Auth Proxy，说是可以在 Grafana 外部进行权限验证，经过通读文档和试验，发现其本质是：通过 web server 校验后，在每个请求上增加一个 header (默认 X-WEBAUTH-USER)来实现免登录\b；文档中的示例是通过 htpasswd 来实现的权限验证，那自然想到可以通过 OpenResty \b进行权限校验。 假设 token 对应的用户信息存在 Redis 中，基本流程如下： 实现细节Auth Proxy本质是增加一个header（默认 X-WEBAUTH-USER）； Grafana 开启Auth Proxy；配置：12345678910[auth.proxy]enabled = true; defalut header nameheader_name = X-WEBAUTH-USER; username or emailheader_property = username; 自动注册auto_sign_up = false; 白名单whitelist = 127.0.0.1 OpenResty\bOpenResty的配置为：123456789101112131415161718192021server &#123; listen 80; server_name grafana.com; location / &#123; content_by_lua_file \"/usr/local/etc/openresty/conf.d/grafana.lua\"; # 本质是\b为了加这个 header # proxy_set_header X-WEBAUTH-USER \"longfeihe\"; &#125; location @grafana &#123; proxy_pass http://127.0.0.1:3000; &#125; # 若使用 url 接口鉴权，则开启此 location #location ^~ /proxy/ &#123; # internal; # 内部请求 # proxy_pass http://someone-proxy.com/; # 必须有 / # proxy_set_header Accept \"*/*\"; #&#125;&#125; grafana.lua123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121-- config redis startlocal redisIp = '127.0.0.1'local redisPort = '6379'-- config redis endlocal cjson = require \"cjson\"local redis = require \"resty.redis\"local aes = require \"resty.aes\"local function getToken() local args = ngx.req.get_uri_args() local token = args['token'] return tokenendfunction conRedis(ip, port) local red = redis.new() local ok, err = red:connect(ip, port) red:set_timeout(1000) -- 1s if not ok then ngx.log(ngx.ERR, 'connect redis fail') ngx.exit(ngx.HTTP_SERVICE_UNAVAILABLE) end ngx.log(ngx.INFO, 'connect redis success') return redendlocal function getUsernameByRedis(token) local red = conRedis(redisIp, redisPort) token = ngx.md5(token .. '_sso') ngx.log(ngx.INFO, 'fetch redis key:' .. token) local value = red:get(token) closeRedis(red) if value ~= ngx.null then obj = cjson.decode(value) local username = obj['username'] return username end returnend-- 使用 url 鉴权function getUsernameByUrl(token) local uri = \"/proxy/get-user-info\" -- 这里接口地址按实际情况进行修改 --ngx.req.set_header(\"X-TOKEN\", token) res = ngx.location.capture(uri, &#123; method = ngx.HTTP_POST &#125;) if res.body then local data = cjson.decode(res.body) if data[\"code\"] ~= 0 then ngx.log(ngx.ERR, \"request model for get user info was failed; msg:\" .. data[\"message\"]) ngx.exit(ngx.HTTP_BAD_GATEWAY) end local email = data[\"data\"][\"email\"] return email else ngx.log(ngx.ERR, \"request model for get user info was failed; code:\" .. res.status) ngx.exit(ngx.HTTP_BAD_GATEWAY) endendfunction closeRedis(redis) local ok, err = redis:close() if not ok then ngx.log(ngx.ERR, 'close redis connect fail') return end ngx.log(ngx.INFO, 'close redis connect success')endlocal function setHeader(username) ngx.log(ngx.INFO, 'X-WEBAUTH-USER:' .. username) ngx.req.set_header(\"X-WEBAUTH-USER\", username)endlocal function setCookie(username) ngx.header['Set-Cookie'] = &#123; 'token=' .. encrypt(username) &#125;endlocal function getUsernameByCookie() local token = ngx.var.cookie_token return decrypt(token)endlocal function logout() if ngx.re.match(ngx.var.request_uri, \"logout\") then ngx.header['Set-Cookie'] = &#123; 'token=' &#125; endendfunction encrypt(encryptString) local aes_128_cbc_md5 = aes:new(\"AKeyForAES\") return ngx.encode_base64(aes_128_cbc_md5:encrypt(encryptString))endfunction decrypt(decryptString) local aes_128_cbc_md5 = aes:new(\"AKeyForAES\") local decrypt = ngx.decode_base64(decryptString) return aes_128_cbc_md5:decrypt(decrypt)end-- mainlogout()local token = getToken()if token then ngx.log(ngx.INFO, 'get token:' .. token) local username = getUsernameByRedis(token) if username then setHeader(username) setCookie(username) end ngx.exec(\"@grafana\")else local username = getUsernameByCookie() if username then setHeader(username) end ngx.exec(\"@grafana\")end 参考资料 Auth Proxy Authentication OpenResty","tags":[{"name":"grafana","slug":"grafana","permalink":"http://www.helongfei.com/tags/grafana/"},{"name":"openresty","slug":"openresty","permalink":"http://www.helongfei.com/tags/openresty/"},{"name":"lua","slug":"lua","permalink":"http://www.helongfei.com/tags/lua/"}],"categories":[{"name":"监控","slug":"监控","permalink":"http://www.helongfei.com/categories/监控/"}]},{"title":"Open-Falcon 浅析","date":"2019-06-11T15:44:00.000Z","path":"2019/open-falcon-浅析/","text":"监控系统概述在监控系统领域，相信大家都经历过 Zabbix 的时代；在公司刚起步，机器数量不多时，Zabbix 可以很好的满足我们的需求，但是随着业务的发展，Zabbix 的存储会成为主要的性能瓶颈，从而引发很多问题，增加运维成本。 近些年来，随着互联网技术的不断发展，技术架构的不断演进，监控领域有两个我值得推荐的开源系统：一个是小米出品的 Open-Falcon，一个是基于 Google Borgmon 的开源实现 Prometheus。 今天主要介绍下 Open-Falcon。 Open-Falcon 有如下特点： 强大灵活的数据采集：自动发现，支持falcon-agent、snmp、支持用户主动push、用户自定义插件支持、opentsdb data model like（timestamp、endpoint、metric、key-value tags） 水平扩展能力：支持每个周期上亿次的数据采集、告警判定、历史数据存储和查询 高效率的告警策略管理：高效的portal、支持策略模板、模板继承和覆盖、多种告警方式、支持callback调用 人性化的告警设置：最大告警次数、告警级别、告警恢复通知、告警暂停、不同时段不同阈值、支持维护周期 高效率的graph组件：单机支撑200万metric的上报、归档、存储（周期为1分钟） 高效的历史数据query组件：采用rrdtool的数据归档策略，秒级返回上百个metric一年的历史数据 dashboard：多维度的数据展示，用户自定义Screen 高可用：整个系统无核心单点，易运维，易部署，可水平扩展 开发语言： 整个系统的后端，全部golang编写，portal和dashboard使用python编写。 简而言之：Open-falcon 是一个模块化、高可用、高性能、支持水平扩展的监控告警系统，支持机器监控、业务监控、各种开源软件的监控。 架构 Agent 数据采集组件 部署在业务机器上，主要作用： 自动采集预先定义的各种采集项（机器级别的监控指标） agent 还提供一个 HTTP 接口（/v1/push），用于接收用户自定义上报数据 每隔60秒，通过 JsonRPC push 数据到 Transfer 模块（使用长连接）。 Transfer 数据转发服务 主要作用： 接收 agent 上报的数据 按照哈希规则进行数据分片，并将分片后的数据分别 push 给 graph、judge 等组件 Graph 存储绘图数据、历史数据 主要作用： 接口 transfer 推送数据 处理 API 组件的查询请求、返回绘图数据 API 绘图数据的查询接口 主要作用：根据一致性哈希算法去相应的 graph 实例查询不同监控项的数据，汇总后返回 Dashboard 面向用户的查询界面 Judge 告警判断 因为数据量太大，此组件放在 transfer 组件之后，这样每个 judge 只需要处理一小部分数据；主要作用： 接口 transfer 推送数据 分析数据，判断是否触发告警，需要告警则写入 redis 部署一个 judge 实例处理50万~100万数据，用个5G~10G内存。 Alarm 处理告警事件 主要作用： 从 redis 读取数据，触发动作（短信、邮件、回调等） 告警合并 已经发送的告警信息存入 MySQL，默认存7天 alarm是个单点，因为未恢复的告警是放到alarm的内存中的，alarm还需要做报警合并。需要做好存活监控。 HBS 心跳服务器(Heartbeat Server) 至少部署两个实例以保证可用性，一般一个实例可以搞定5000台机器；主要作用： 所有 agent 都会连到 HBS，每分钟发一次心跳请求，并告知 agent 应该采集哪些端口和进程 维护业务机器的信息（host 表） 告知 judge 报警策略 Nodata 检测监控数据的上报异常 主要作用：配置了nodata的采集项超时未上报数据，nodata生成一条默认的模拟数据 Aggregator 集群聚合 主要作用：聚合某集群下的所有机器的某个指标的值，提供一种集群视角的监控体验 Task 定时任务 主要作用： index更新。包括图表索引的全量更新 和 垃圾索引清理。 falcon服务组件的自身状态数据采集。定时任务采集了transfer、graph、task这三个服务的内部状态数据。 falcon自检控任务 设计理念数据采集 制定接口规范，以此接入各种监控数据 agent 自发现采集各种 Linux 性能指标，无需配置 由 HBS 下发各种采集指标、策略 支持 plugin；用户把插件提交到指定的 git repo，server端提供一个配置，哪些机器应该执行哪些插件，通过 HBS 把这个信息分发给 agent，agent 每隔一段时间去 git pull 这个 git repo，采集脚本就完成了分发。执行周期通过解析文件名来执行：60_action.sh，60s 执行一次。脚本执行完了，把输出打印到stdout，agent 截获之后 push 给 server TagTag 是一种聚合手段，可以用更少的配置覆盖更多的监控项。例如：123456789&#123; \"endpoint\": \"qd-sadev-falcon-judge01.hd\", \"metric\": \"latency\", \"tags\": \"department=sadev,project=falcon,module=judge,method=falcon.judge.rpc.send\", \"value\": 10.2, \"timestamp\": 1427204756, \"step\": 60, \"counterType\": \"GAUGE\"&#125; 如果我们这么配置：latency/department=sadev all(#2) &gt; 20，意味着对sadev这个部门的所有接口的latency都做了策略配置。 模板继承同一个部门的机器，根据不同的业务对监控策略的要求是不一样的，比如业务 A 复杂高，load.1min &gt; 10 就报警，业务 B 复杂低，load.1min &gt; 5 就报警。若不支持模板继承，则需要配置两份策略，而模板继承就减少了此类工作量。 数据存储Open-falcon 把数据按照用途分成两类，一类是用来绘图的，一类是用户做数据挖掘的。关于绘图数据，在数据每次存入的时候，会自动进行采样、归档。我们的归档策略如下，历史数据保存5年。同时为了不丢失信息量，数据归档的时候，会按照平均值采样、最大值采样、最小值采样存三份。 对于原始数据，transfer会打一份到hbase，也可以直接使用opentsdb 使用\b示例部署参见小米公司部署Open-Falcon的一些实践经验 监控网络 配置告警 上报接口状态上报状态码、耗时等，可监控接口的健康、性能等。 可以做的改进参见Mt-Falcon——Open-Falcon在美团点评的应用与实践 参考资料 Open-Falcon 官方文档","tags":[{"name":"falcon","slug":"falcon","permalink":"http://www.helongfei.com/tags/falcon/"}],"categories":[{"name":"监控","slug":"监控","permalink":"http://www.helongfei.com/categories/监控/"}]},{"title":"开源监控系统浅析","date":"2019-06-09T12:04:00.000Z","path":"2019/开源监控系统浅析/","text":"为什么需要监控系统？监控系统是整个运维体系的重要环节之一，主要服务于运维人员和开发人员；运维人员需要监控硬件、软件、网络等状态，做到故障预警、自动转移、自动恢复等，开发人员需要根据监控数据快速定位问题，提高服务的可用性。尤其是「微服务架构」，若没有监控系统，一但出现故障，定位问题就需要花费大量的时间。 监控系统的核心抽象来看，监控系统最主要的有两部分：监控指标、告警。 监控指标为了实现我们的监控目的，我们需要制定一些监控指标，一般我们可以把监控指标分为：基础监控指标、业务监控指标。 基础监控指标 通常包括CPU、内存、磁盘、端口和进程等机器、网络相关的操作系统级别的信息，一般开源监控软件都提供此类指标的数据采集。 业务监控指标 一般都是由业务系统内部服务产生/上报，反应业务的健康状态。通常采集的有以下几类： 日志。日志是主要的监控数据来源。针对 PHP 来说，通常会采集 web server 的日志、php-fpm 慢日志、web 框架日志、数据库慢日志等。通过日志我们可以分析出大量有用的信息，比如：异常状态码的分布、接口请求量分布、请求延迟、用户地域分布、服务性能瓶颈等；最重要的是，若服务出现异常，我们可以通过日志快速的定位并复现问题。日志类的数据采集，一般监控软件都会提供日志采集插件，除此之外还可以使用 Elastic Stack 。 接口。一般对外接口都需要提供健康接口；针对分布式服务，需要 Trace 系统来追踪整个请求链。 命令行。一些开源软件提供本地的命令来输出监控指标，比如 Nginx、MySQL、PHP-FPM、Redis等 上报。可以通过插件、埋点等方式主动 push 监控指标给监控系统。 告警告警最主要的是：收敛、可用性。 收敛 收敛问题主要体现在：告警信息多，关联告警多，运维期间不断告警。 可用性 可用性问题主要体现在：监控与告警耦合在一起。 常见的开源监控系统 项目 Prometheus Open-falcon Zabbix 自动发现 YES YES YES Agent YES YES YES SNMP YES YES YES 外部脚本 NO YES YES 插件 YES YES YES 告警 YES YES YES 数据储存方法 TSDB MySQL/OpenTSDB/Redis MySQL 报表 NO NO YES 开发语言 Go Go Python C PHP 用户权限 NO NO 灵活分配 在公司起步阶段，基本都选择 zabbix，但随着业务发展 zabbix 在数据存储上有很大的瓶颈；这时可以选择 open-falcon 或者 prometheus；若是微服务(容器化)，使用 k8s 作为容器编排，那首选 prometheus。 参考资料 监控系统选型Prometheus、TICK、Open-falcon、Zabbix 常见开源告警系统对比分析(prometheus、open-falcon、zabbix)","tags":[{"name":"falcon","slug":"falcon","permalink":"http://www.helongfei.com/tags/falcon/"},{"name":"prometheus","slug":"prometheus","permalink":"http://www.helongfei.com/tags/prometheus/"},{"name":"zabbix","slug":"zabbix","permalink":"http://www.helongfei.com/tags/zabbix/"}],"categories":[{"name":"监控","slug":"监控","permalink":"http://www.helongfei.com/categories/监控/"}]},{"title":"Laravel自定义用户权限校验","date":"2017-12-29T16:05:00.000Z","path":"2017/laravel自定义用户权限校验/","text":"背景在现实的架构中，帐号体系往往会单独维护，应用需要鉴权的时候会请求用户中心接口，而laravel使用auth中间件时默认采用的是session进行鉴权，不能满足我们的需求，所以需要自定义权限校验。 Auth 中间件的工作原理 首先，在 app/Http/Kernel.php 中，发现 :12345protected $routeMiddleware = [ 'auth' =&gt; \\Illuminate\\Auth\\Middleware\\Authenticate::class, 'auth.basic' =&gt; \\Illuminate\\Auth\\Middleware\\AuthenticateWithBasicAuth::class, ... ]; 然后，跟踪到 vendor/laravel/framework/src/Illuminate/Auth/AuthManager.php 123456789101112131415public function guard($name = null)&#123; $name = $name ?: $this-&gt;getDefaultDriver(); return isset($this-&gt;guards[$name]) ? $this-&gt;guards[$name] : $this-&gt;guards[$name] = $this-&gt;resolve($name);&#125;...public function getDefaultDriver()&#123; // 注意这行 return $this-&gt;app['config']['auth.defaults.guard'];&#125; 然后，查看 config/auth.php :123456789101112131415...'defaults' =&gt; [ 'guard' =&gt; 'web', // 注意这行 'passwords' =&gt; 'users', ],...'guards' =&gt; [ 'web' =&gt; [ 'driver' =&gt; 'session', 'provider' =&gt; 'users', ], ... ],... 由此可见，默认使用的guard是web，驱动是session；到此已经很明确了，我们需要做的只是新建一个guard。 具体如何创建guard？见官方文档：https://laravel.com/docs/5.5/authentication#adding-custom-guards 举个例子 创建 guard 12345678910111213141516171819202122232425262728293031323334353637383940414243namespace App;use Illuminate\\Auth\\GuardHelpers;use Illuminate\\Contracts\\Auth\\Guard;use Illuminate\\Http\\Request;class KohanaGuard implements Guard&#123; use GuardHelpers; protected $request; public function __construct(Request $request) &#123; $this-&gt;request = $request; &#125; /** * Get the currently authenticated user. * * @return \\Illuminate\\Contracts\\Auth\\Authenticatable|null * @throws \\Exception */ public function user() &#123; // 校验规则 // 成功返回 User Model 对象 // 失败返回 null &#125; /** * Validate a user's credentials. * * @param array $credentials * * @return bool */ public function validate(array $credentials = []) &#123; // TODO: Implement validate() method. &#125;&#125; 添加到 app/Providers/AuthServiceProvider.php: 12345678910public function boot()&#123; $this-&gt;registerPolicies(); //注册 kohana 的 guard \\Auth::extend('kohana', function ($app, $name, array $config) &#123; return new KohanaGuard($app['request']); &#125;);&#125; 修改 config/auth.php123456789101112131415...'defaults' =&gt; [ 'guard' =&gt; 'kohana', // 注意这行 'passwords' =&gt; 'users',],...'guards' =&gt; [ ... // 以下为新增 'kohana' =&gt; [ 'driver' =&gt; 'kohana', 'provider' =&gt; 'users', ],],...","tags":[{"name":"php","slug":"php","permalink":"http://www.helongfei.com/tags/php/"},{"name":"laravel","slug":"laravel","permalink":"http://www.helongfei.com/tags/laravel/"}],"categories":[{"name":"PHP","slug":"PHP","permalink":"http://www.helongfei.com/categories/PHP/"}]},{"title":"CI 框架总结","date":"2016-03-26T19:09:54.000Z","path":"2016/cikuang-jia-zong-jie/","text":"本文主要是参考2.2.6的源码 设计思想使用 &amp;get_instance(); 可以引用所有已加载的类。 中文手册http://codeigniter.org.cn/userguide2/index.html 框架运行图解运行流程图 运行生命周期 开发注意事项Controller 中 _remap 方法（接管路由） _output 方法（接管输出） _前缀的方法名都会被路由屏蔽 如何扩展框架？扩展/替换 core 类 此类都是在系统使用的核心类，常用的是扩展控制器类 在 application/core 下新建文件 扩展 1class MY_controller extends CI_controller&#123;&#125; 替换 1class CI_controller&#123;&#125; 使用/新建/替换/扩展类库 使用内置 1$this-&gt;load-&gt;library('name'); 建立新的类 在 applicatioin/libraries 目录下 扩展已有类 在 applicatioin/libraries 目录下，使用定义好的子类前缀，并继承父类 比如扩展 email： 1class MY_Email extends CI_Email&#123;&#125; 替换已有类 在 applicatioin/libraries 目录下，声明和默认的类名一样的类 使用/新建适配器 内置 123$this-&gt;load-&gt;driver('some_parent');$this-&gt;some_parent-&gt;some_method();$this-&gt;some_parent-&gt;child_one-&gt;some_method(); 自定义 目录结构： 123456/application/libraries/Driver_name Driver_name.php drivers Driver_name_subclass_1.php Driver_name_subclass_2.php Driver_name_subclass_3.php 集成自己的独立应用目录结构： 123456/application/third_party/foo_barconfig/helpers/language/libraries/models/ 使用方法： 1234$this-&gt;load-&gt;add_package_path(APPPATH.'third_party/foo_bar/');$this-&gt;load-&gt;library('foo_bar');...$this-&gt;load-&gt;remove_package_path(APPPATH.'third_party/foo_bar/'); 坑 默认保存 SQL；cli 模式下会内存溢出;修复方式如下： 12345在配置文件中增加：$db['default']['save_queries'] = false;或者在代码里增加:$this-&gt;load-&gt;database();$this-&gt;db-&gt;save_queries = false;","tags":[{"name":"php","slug":"php","permalink":"http://www.helongfei.com/tags/php/"},{"name":"CI","slug":"CI","permalink":"http://www.helongfei.com/tags/CI/"}],"categories":[{"name":"PHP","slug":"PHP","permalink":"http://www.helongfei.com/categories/PHP/"}]}]}